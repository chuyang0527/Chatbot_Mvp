# å¿«é€Ÿå¼€å§‹æŒ‡å—

5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹èŠå¤©æœºå™¨äºº RAG ç³»ç»Ÿã€‚

## ğŸš€ æœ€å¿«æ–¹å¼ï¼šDocker ä¸€é”®éƒ¨ç½²

### å‰ç½®è¦æ±‚

- âœ… å·²å®‰è£… Docker Desktop
- âœ… è‡³å°‘ 8GB å¯ç”¨å†…å­˜
- âœ… ç¨³å®šçš„ç½‘ç»œè¿æ¥

### æ­¥éª¤

#### 1. å…‹éš†é¡¹ç›®

```bash
git clone <your-repo-url>
cd chatbot-rag
```

#### 2. ä¸€é”®å¯åŠ¨

**Linux/macOS:**
```bash
chmod +x scripts/setup.sh
./scripts/setup.sh
```

**Windows PowerShell:**
```powershell
.\scripts\setup.ps1
```

#### 3. ä¸‹è½½ AI æ¨¡å‹

```bash
# ç­‰å¾… Ollama æœåŠ¡å¯åŠ¨ï¼ˆçº¦ 30 ç§’ï¼‰
docker-compose ps

# ä¸‹è½½ DeepSeek æ¨¡å‹ï¼ˆçº¦ 4GBï¼Œéœ€è¦å‡ åˆ†é’Ÿï¼‰
docker exec -it chatbot-ollama ollama pull deepseek-r1:7b
```

#### 4. å¼€å§‹èŠå¤©

```bash
docker exec -it chatbot-app python src/main.py
```

### ğŸ‰ å®Œæˆï¼

ç°åœ¨ä½ å¯ä»¥ï¼š

```
ä½ : upload example.pdf
âœ“ æ–‡æ¡£å·²æˆåŠŸä¸Šä¼ å¹¶å‘é‡åŒ–

ä½ : è¿™ä¸ªæ–‡æ¡£è®²äº†ä»€ä¹ˆï¼Ÿ
æœºå™¨äºº: æ ¹æ®æ–‡æ¡£å†…å®¹ï¼Œè¿™æ˜¯å…³äº...
```

---

## ğŸ’» æœ¬åœ°å¼€å‘æ–¹å¼

é€‚åˆéœ€è¦ä¿®æ”¹ä»£ç çš„å¼€å‘è€…ã€‚

### å‰ç½®è¦æ±‚

- Python 3.10+
- Ollama

### æ­¥éª¤

#### 1. å®‰è£… uvï¼ˆPython åŒ…ç®¡ç†å™¨ï¼‰

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### 2. å®‰è£…ä¾èµ–

```bash
git clone <your-repo-url>
cd chatbot-rag
make install
```

#### 3. ä¸‹è½½æ¨¡å‹

```bash
# Embedding æ¨¡å‹
make download-models

# LLM æ¨¡å‹
ollama pull deepseek-r1:7b
```

#### 4. å¯åŠ¨åº”ç”¨

```bash
make dev
```

---

## ğŸ“ åŸºæœ¬ä½¿ç”¨

### ä¸Šä¼ æ–‡æ¡£

æ”¯æŒæ ¼å¼ï¼šPDFã€Wordã€Markdownã€TXT

```bash
ä½ : upload /path/to/document.pdf
âœ“ æ–‡æ¡£å·²æˆåŠŸä¸Šä¼ å¹¶å‘é‡åŒ–
```

### æé—®

```bash
ä½ : æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ
æœºå™¨äºº: æ ¹æ®æ–‡æ¡£ï¼Œä¸»è¦å†…å®¹åŒ…æ‹¬...

ä½ : èƒ½è¯¦ç»†è¯´è¯´ç¬¬äºŒéƒ¨åˆ†å—ï¼Ÿ
æœºå™¨äºº: ç¬¬äºŒéƒ¨åˆ†ä¸»è¦è®¨è®ºäº†...
```

### ç®¡ç†å‘½ä»¤

```bash
clear    # æ¸…ç©ºå‘é‡åº“
history  # æ¸…ç©ºå¯¹è¯å†å²
help     # æ˜¾ç¤ºå¸®åŠ©
exit     # é€€å‡ºç¨‹åº
```

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### Docker æ–¹å¼

```bash
# å¯åŠ¨æœåŠ¡
docker-compose up -d

# åœæ­¢æœåŠ¡
docker-compose down

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# é‡å¯æœåŠ¡
docker-compose restart
```

### æœ¬åœ°æ–¹å¼

```bash
# å¯åŠ¨åº”ç”¨
make dev

# è¿è¡Œæµ‹è¯•
make test

# ä»£ç æ£€æŸ¥
make lint

# æ ¼å¼åŒ–ä»£ç 
make format
```

---

## âš™ï¸ é…ç½®ï¼ˆå¯é€‰ï¼‰

### ç¯å¢ƒå˜é‡

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```env
# LLM é…ç½®
OLLAMA_MODEL=deepseek-r1:7b
LLM_TEMPERATURE=0.7

# æ–‡æ¡£å¤„ç†
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# LangSmith è¿½è¸ªï¼ˆå¯é€‰ï¼‰
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_key
```

### æ¨¡å‹é€‰æ‹©

```bash
# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
ollama list

# åˆ‡æ¢æ¨¡å‹
# ç¼–è¾‘ .env ä¸­çš„ OLLAMA_MODEL
```

---

## ğŸ› é‡åˆ°é—®é¢˜ï¼Ÿ

### Ollama è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
docker-compose ps ollama

# é‡å¯ Ollama
docker-compose restart ollama
```

### å†…å­˜ä¸è¶³

```bash
# å¢åŠ  Docker å†…å­˜é™åˆ¶
# Docker Desktop -> Settings -> Resources -> Memory (å»ºè®® 8GB+)
```

### æ¨¡å‹ä¸‹è½½æ…¢

```bash
# ä½¿ç”¨å›½å†…é•œåƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
# æˆ–è€…æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶
```

### æ›´å¤šé—®é¢˜

æŸ¥çœ‹ [å®Œæ•´æ–‡æ¡£](../README.md) æˆ– [éƒ¨ç½²æŒ‡å—](DEPLOYMENT.md)

---

## ğŸ“š ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [å®Œæ•´æ–‡æ¡£](../README.md)
- ğŸ”§ æŸ¥çœ‹ [éƒ¨ç½²æŒ‡å—](DEPLOYMENT.md)
- ğŸ¤ äº†è§£ [è´¡çŒ®æŒ‡å—](../CONTRIBUTING.md)
- ğŸ’¡ æµè§ˆ [ç¤ºä¾‹ä»£ç ](../examples/)

---

## ğŸ¯ å¿«é€Ÿæµ‹è¯•

æƒ³å¿«é€Ÿæµ‹è¯•ç³»ç»Ÿï¼Ÿè¯•è¯•è¿™ä¸ªï¼š

```bash
# 1. åˆ›å»ºæµ‹è¯•æ–‡æ¡£
echo "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚" > test.txt

# 2. ä¸Šä¼ æ–‡æ¡£
ä½ : upload test.txt

# 3. æé—®
ä½ : ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ
```

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€

æœ‰é—®é¢˜ï¼Ÿ[æäº¤ Issue](https://github.com/yourusername/chatbot-rag/issues)
