# Ollama 配置
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b

# LLM 参数
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# 文档处理参数
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# 检索参数
RETRIEVAL_K=4

# LangSmith 配置（可选）
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_api_key_here
LANGCHAIN_PROJECT=chatbot-rag
